{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "905e9270-a0a4-4865-863d-49709d9c00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b265c8c-000a-4dd1-b09e-35d94745aa33",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32303079-1bc3-4bce-ace2-30b65eb51aa2",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3dc0c23-df7d-4455-8e69-592895ee1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------LR FUNCTIONS--------------------#\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def log_loss(y_true, y_pred):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.maximum(epsilon, y_pred)\n",
    "    y_pred = np.minimum(1 - epsilon, y_pred)\n",
    "    return - (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "def gradient_descent(X, y, learning_rate, num_epochs):\n",
    "    num_samples, num_features = X.shape\n",
    "    weights = np.zeros(num_features)\n",
    "    bias = 0\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        z = np.dot(X, weights) + bias\n",
    "        y_pred = sigmoid(z)\n",
    "\n",
    "        training_loss = np.mean(log_loss(y, y_pred))\n",
    "        training_losses.append(training_loss)\n",
    "\n",
    "        dw = (1/num_samples) * np.dot(X.T, (y_pred - y))\n",
    "        db = (1/num_samples) * np.sum(y_pred - y)\n",
    "\n",
    "        weights -= learning_rate * dw\n",
    "        bias -= learning_rate * db\n",
    "        z_val = np.dot(X_val, weights) + bias\n",
    "        y_pred_val = sigmoid(z_val)\n",
    "        validation_loss = np.mean(log_loss(y_val, y_pred_val))\n",
    "        validation_losses.append(validation_loss)\n",
    "\n",
    "    return weights, bias, training_losses, validation_losses\n",
    "\n",
    "def classify(X, weights, threshold=0.5):\n",
    "    z = np.dot(X, weights)\n",
    "    y_pred = sigmoid(z)\n",
    "    return (y_pred >= threshold).astype(int)\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_measure = 2 * (precision * recall) / (precision + recall)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    return precision, recall, f_measure, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe59b9a-de92-4fd9-bf03-da572c9a23df",
   "metadata": {},
   "source": [
    "## ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a202ba52-f959-4879-a235-74211c64e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------ROC AND FUNCTIONS--------------------#\n",
    "def calc_TPR(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    # print(f\"tp are {tp}\")\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    # print(f\"fn are {fn}\")\n",
    "    \n",
    "    return tp / (tp + fn)\n",
    "    \n",
    "\n",
    "def calc_FPR(y_true, y_pred):\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    # print(f\"fp are {fp}\")\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    # print(f\"tn are {tn}\")\n",
    "    \n",
    "    return fp / (fp + tn)\n",
    "\n",
    "\n",
    "def make_roc_df(X_inp, weights_inp, y_true_inp):\n",
    "    pred_dict = {\"threshold\": [],\n",
    "                 \"tpr\": [],\n",
    "                 \"fpr\": [],\n",
    "                 \"accuracy\": [],\n",
    "                 \"f1-measure\": [],\n",
    "                 \"precision\": [],\n",
    "                 \"recall\": []\n",
    "                }\n",
    "    \n",
    "    # thresholds = [0.1, 0.4, 0.7, 0.9]\n",
    "    thresholds = [i/100 for i in range(0, 100+1)] # 0 to 1, by 0.01 steps\n",
    "    # print(thresholds)\n",
    "    for thr in thresholds:\n",
    "        pred_dict[\"threshold\"].append(thr)\n",
    "        # print(f\"threshold is {thr}\")\n",
    "        y_pred_calc = classify(X = X_inp, \n",
    "                               weights = weights_inp, \n",
    "                               threshold = thr)\n",
    "        \n",
    "        tpr = calc_TPR(y_true_inp, y_pred_calc)\n",
    "        pred_dict[\"tpr\"].append(tpr)\n",
    "        # print(f\"TPR is {tpr}\")\n",
    "        fpr = calc_FPR(y_true_inp, y_pred_calc)\n",
    "        pred_dict[\"fpr\"].append(fpr)\n",
    "        # print(f\"FPR is {fpr}\")\n",
    "        precision, recall, f_measure, accuracy = evaluate(y_true_inp, y_pred_calc)\n",
    "        pred_dict[\"accuracy\"].append(accuracy)\n",
    "        pred_dict[\"f1-measure\"].append(f_measure)\n",
    "        pred_dict[\"precision\"].append(precision)\n",
    "        pred_dict[\"recall\"].append(recall)\n",
    "        # print()\n",
    "    \n",
    "    return pd.DataFrame(pred_dict)\n",
    "\n",
    "def calc_AUC(df_roc_inp):\n",
    "    \n",
    "    df_roc_inp_sorted = df_roc_inp.sort_values([\"fpr\"])\n",
    "    \n",
    "    auc = np.trapz(y=df_roc_inp_sorted[\"tpr\"], \n",
    "                   x=df_roc_inp_sorted[\"fpr\"],\n",
    "                  )\n",
    "    \n",
    "    return auc\n",
    "\n",
    "def roc_curves_LR(X_train_inp, y_train_inp, X_val_inp, y_val_inp, learning_rate_lst, num_epochs):\n",
    "    \n",
    "    df_graph_lst = []\n",
    "    auc_dict = {\"learning_rate\": [],\n",
    "                \"AUC\": []\n",
    "               }\n",
    "    \n",
    "    for l_rate in learning_rate_lst:\n",
    "        weights, bias, training_losses, validation_losses = gradient_descent(X_train_inp, \n",
    "                                                                             y_train_inp, \n",
    "                                                                             l_rate, \n",
    "                                                                             num_epochs)\n",
    "        \n",
    "        calculate_weight_impact(X_train_inp, weights, l_rate)\n",
    "        df_graph_inp = make_roc_df(X_val_inp, weights, y_val_inp)\n",
    "        df_graph_inp[\"learning_rate\"] = l_rate\n",
    "                \n",
    "        df_graph_lst.append(df_graph_inp)\n",
    "        \n",
    "        auc_dict[\"learning_rate\"].append(l_rate)\n",
    "        auc_dict[\"AUC\"].append(calc_AUC(df_graph_inp))\n",
    "        \n",
    "    df_graph = pd.concat(df_graph_lst)\n",
    "    df_graph.to_csv('table_of_error_metrics.csv')\n",
    "    df_auc = pd.DataFrame(auc_dict)\n",
    "    \n",
    "    fig = px.line(df_graph,\n",
    "                  title=f\"ROC for Logistic Regression with varied Learning Rates and {num_epochs} Epochs\",\n",
    "                  x=\"fpr\",\n",
    "                  y=\"tpr\",\n",
    "                  hover_data = [\"threshold\", \"tpr\", \"fpr\", \"learning_rate\"],\n",
    "                  color=\"learning_rate\",\n",
    "                  template=\"plotly_white\",\n",
    "                  # markers=True,\n",
    "                  width=800,\n",
    "                  height=600,\n",
    "                  labels={\"tpr\": \"TPR\", \"fpr\": \"FPR\", \"learning_rate\": \"Learning Rate\"}\n",
    "                 )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return df_graph, df_auc, fig    \n",
    "\n",
    "def calculate_weight_impact(X_train, weights, l_rate):\n",
    "    # weights_array = np.array(list(zip))\n",
    "    weights_df = pd.DataFrame({'Weight': weights})\n",
    "    # print(X_train)\n",
    "    # weights_df.to_csv('weights' + str(l_rate) + '.csv')\n",
    "    # print(weights_df)\n",
    "\n",
    "    weights_df['Absolute_Weight'] = weights_df['Weight'].abs()\n",
    "    sorted_weights = weights_df.sort_values(by='Absolute_Weight', ascending=False)\n",
    "\n",
    "    # Print the sorted DataFrame\n",
    "    print(sorted_weights)\n",
    "    sorted_weights.to_csv('weights' + str(l_rate) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a79ba-bfc6-4393-8356-9a5531650f0d",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d51f2e-71cf-4422-a893-3b62a4116d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Shuffle input data matrix @X and @y, splitting based on proportion to go to training data @train_size_prop.\n",
    "\n",
    "Keeps proportion of class labels consistent across training set and validation set (to ensure validation set will contain desired proportion of class labels to verify against).\n",
    "'''\n",
    "\n",
    "def shuffle_by_class_split(X, y, train_size_prop):\n",
    "    from math import ceil\n",
    "    np.random.seed(seed=0)\n",
    "    uniq_classes = np.unique(y)\n",
    "    \n",
    "    train_i = []\n",
    "    val_i = []\n",
    "    \n",
    "    # Build list of indices where samples have given class label. Adds first 2/3 of shuffled indices to train_i, and last 1/3 to val_i.\n",
    "    for label in uniq_classes:\n",
    "\n",
    "        filt_ind = np.array(ind_where_true(y, label))\n",
    "\n",
    "        shuffled_ind = filt_ind.copy()\n",
    "        np.random.shuffle(shuffled_ind)\n",
    "\n",
    "\n",
    "        train_size_last_index = ceil(train_size_prop * (len(shuffled_ind)-1))\n",
    "\n",
    "\n",
    "        train_i += list(shuffled_ind[:train_size_last_index])\n",
    "\n",
    "        val_i += list(shuffled_ind[train_size_last_index:])\n",
    "    \n",
    "    # Training and validation sets filtered down based on lists indices built earlier\n",
    "    X_train, X_val = X[train_i], X[val_i]\n",
    "    y_train, y_val = y[train_i], y[val_i]\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7812c2da-4e64-4b57-aa27-418329b3963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###----------FUNCTIONS----------###\n",
    "'''\n",
    "Makes training and validation sets for input data matrix @dat into S cross-validation folds. \n",
    "\n",
    "Iterates S times, setting seed to value of iteration index. Divides dataset into S folds, with last fold being slightly larger and containing remainder of data due to potential rounding of indices used to slice dataset. The i-th fold is the validation set, and concatentates other folds together to form training set.\n",
    "\n",
    "Stores arrays corresponding to training and validation X and y into a dictionary, assuming last column is y as per problem requirements.\n",
    "'''\n",
    "def cv_shuffle_split(dat, S):\n",
    "    cv_dict = {}\n",
    "    for i in range(1, S+1):\n",
    "\n",
    "        # Shuffle data\n",
    "        # np.random.seed(seed=i)\n",
    "        dat_shuffled = dat.copy()\n",
    "        np.random.shuffle(dat_shuffled)\n",
    "        \n",
    "        # Define test set fold\n",
    "\n",
    "        fold_size = int(np.around(len(dat_shuffled) / S, 0))\n",
    "        \n",
    "        ## Label start and stop indices for test fold\n",
    "        ind_start_val = (i-1) * fold_size\n",
    "\n",
    "\n",
    "        if i != S:\n",
    "            ind_end_val = i * fold_size\n",
    "        else:\n",
    "            ind_end_val = len(dat_shuffled)\n",
    "\n",
    "    \n",
    "        dat_val = dat_shuffled[ind_start_val:ind_end_val, :]\n",
    "        \n",
    "        # Define train set made up of all other folds\n",
    "        pre_val_slice = dat_shuffled[:ind_start_val, :]\n",
    "        post_val_slice = dat_shuffled[ind_end_val:, :]\n",
    "\n",
    "        dat_train = np.concatenate((pre_val_slice,\n",
    "                                    post_val_slice))\n",
    "        \n",
    "        \n",
    "        \n",
    "        cv_dict[i] = {\"X_train_cv\": dat_train[:, :-1],\n",
    "                      \"y_train_cv\": dat_train[:, -1],\n",
    "                      \"X_val_cv\": dat_val[:, :-1],\n",
    "                      \"y_val_cv\": dat_val[:, -1]\n",
    "                     }\n",
    "    \n",
    "    return cv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d2dc6-ba40-4757-a24f-5b8e7c603110",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d46b213e-49ce-4c86-a044-0e18cabc2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is shuffled\n",
    "\n",
    "train_path = \"./pre_processing/output/training_data_resampled_encoded.csv\"\n",
    "val_path = \"./pre_processing/output/validation_data_encoded.csv\"\n",
    "\n",
    "#train_path = \"training_data_resampled_encoded.csv\"\n",
    "#val_path = \"validation_data_encoded.csv\"\n",
    "\n",
    "bank_training = pd.read_csv(train_path)\n",
    "bank_validation = pd.read_csv(val_path)\n",
    "\n",
    "# Step 4: Standardize the features\n",
    "X_train = bank_training.iloc[:, :-1].values\n",
    "y_train = bank_training.iloc[:, -1].values\n",
    "X_val = bank_validation.iloc[:, :-1].values\n",
    "y_val = bank_validation.iloc[:, -1].values\n",
    "\n",
    "# Add a bias to X_Train and X_val\n",
    "ones_column = np.ones((X_train.shape[0], 1))\n",
    "X_train = np.c_[ones_column, X_train]\n",
    "ones_column = np.ones((X_val.shape[0], 1))\n",
    "X_val = np.c_[ones_column, X_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca4995e6-9d39-439a-beb0-670139c598e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48730, 83)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_train = np.c_[X_train, y_train]\n",
    "dat_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79f0ce-c63c-485b-87c9-719c00ab86ce",
   "metadata": {},
   "source": [
    "# Cross Validation with different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14166482-674c-4102-bbeb-5d55ebf320cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_train_cv': array([[1., 1., 0., ..., 0., 0., 1.],\n",
       "        [1., 0., 1., ..., 0., 0., 1.],\n",
       "        [1., 0., 1., ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 1.],\n",
       "        [1., 0., 0., ..., 0., 0., 1.],\n",
       "        [1., 0., 0., ..., 0., 0., 1.]]),\n",
       " 'y_train_cv': array([0., 0., 1., ..., 1., 1., 1.]),\n",
       " 'X_val_cv': array([[1., 1., 0., ..., 0., 0., 1.],\n",
       "        [1., 0., 0., ..., 0., 0., 1.],\n",
       "        [1., 0., 1., ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 1.],\n",
       "        [1., 1., 0., ..., 0., 0., 1.],\n",
       "        [1., 1., 0., ..., 0., 0., 1.]]),\n",
       " 'y_val_cv': array([0., 1., 0., ..., 0., 0., 0.])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train = cv_shuffle_split(dat_train, 5)\n",
    "cv_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84de8ffb-035b-4169-bd16-198622c7fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_scores(cv_dict, params_dict):\n",
    "    \n",
    "    # Dictionary to keep track of performance\n",
    "    performance_dict = {\"learning_rate\": [],\n",
    "                        \"fold\": [],\n",
    "                        \"auc\": []}\n",
    "    \n",
    "    # Iterate over CV folds\n",
    "    for l_rate in params_dict[\"learning_rate\"]:\n",
    "        for fold in cv_dict:\n",
    "            # Calculate weight using training set of fold\n",
    "            weights, bias, training_loss, validation_losses = gradient_descent(cv_dict[fold][\"X_train_cv\"],\n",
    "                                                                               cv_dict[fold][\"y_train_cv\"],\n",
    "                                                                               l_rate,\n",
    "                                                                               100\n",
    "                                                                              )\n",
    "\n",
    "            # Calculate AUC of validation set for each CV fold. Uses fitted weights.\n",
    "            thresholds = [i/100 for i in range(0, 100+1)] # 0 to 1, by 0.01 steps\n",
    "            tpr_lst = []\n",
    "            fpr_lst = []\n",
    "\n",
    "            ## Generate ROC values for curve\n",
    "            for thr in thresholds:\n",
    "                y_val_pred_cv = classify(X = cv_dict[fold][\"X_val_cv\"],\n",
    "                                         weights = weights,\n",
    "                                         threshold = thr)\n",
    "                tpr = calc_TPR(cv_dict[fold][\"y_val_cv\"], y_val_pred_cv)\n",
    "                tpr_lst.append(tpr)\n",
    "\n",
    "                for thr in thresholds:\n",
    "                    y_pred_calc = np.where(y_val_pred_cv >= thr, 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "                fpr = calc_FPR(cv_dict[fold][\"y_val_cv\"], y_val_pred_cv)\n",
    "                fpr_lst.append(fpr)\n",
    "\n",
    "            ## Calculate area\n",
    "            auc = np.abs(np.trapz(y=tpr_lst, \n",
    "                                  x=fpr_lst,\n",
    "                                 )\n",
    "                        )\n",
    "\n",
    "            performance_dict[\"learning_rate\"].append(l_rate)\n",
    "            performance_dict[\"fold\"].append(fold)\n",
    "            performance_dict[\"auc\"].append(auc)\n",
    "\n",
    "    return pd.DataFrame(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdf69ade-e612-450c-b6b0-4121ca3f68a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>fold</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.841394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.832379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.834303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.885781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.877574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.877473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.879252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.911875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.906196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.903847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.905982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.877390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.867150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.864444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.868852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  fold       auc\n",
       "0            0.01     1  0.834817\n",
       "1            0.01     2  0.841394\n",
       "2            0.01     3  0.833897\n",
       "3            0.01     4  0.832379\n",
       "4            0.01     5  0.834303\n",
       "5            0.10     1  0.878366\n",
       "6            0.10     2  0.885781\n",
       "7            0.10     3  0.877574\n",
       "8            0.10     4  0.877473\n",
       "9            0.10     5  0.879252\n",
       "10           1.00     1  0.906325\n",
       "11           1.00     2  0.911875\n",
       "12           1.00     3  0.906196\n",
       "13           1.00     4  0.903847\n",
       "14           1.00     5  0.905982\n",
       "15          10.00     1  0.866074\n",
       "16          10.00     2  0.877390\n",
       "17          10.00     3  0.867150\n",
       "18          10.00     4  0.864444\n",
       "19          10.00     5  0.868852"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict_lr = {\"learning_rate\": [0.01, 0.1, 1, 10],}\n",
    "\n",
    "df_cv_lr = cv_scores(cv_train, params_dict_lr)\n",
    "df_cv_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d1a620-841c-4dab-a1df-0a7108b523c3",
   "metadata": {},
   "source": [
    "### Get learning rate from best AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c524a34-13ef-41ad-850b-707f8843a70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>auc_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.906845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.879689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.868782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.835358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  auc_mean\n",
       "0           1.00  0.906845\n",
       "1           0.10  0.879689\n",
       "2          10.00  0.868782\n",
       "3           0.01  0.835358"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_lr_gba = (df_cv_lr\n",
    "                .groupby([\"learning_rate\"])\n",
    "                .agg(auc_mean = (\"auc\", \"mean\"))\n",
    "                .sort_values(\"auc_mean\", ascending=False)\n",
    "                .reset_index()\n",
    "               )\n",
    "\n",
    "df_cv_lr_gba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa5c00-f41b-4c94-887b-77ef59cbde3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c389b4-6af3-425f-a18d-4b9a45b42900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c242b12-7ffc-40b3-9aa5-cd012ebefaa4",
   "metadata": {},
   "source": [
    "# Best learning rate for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5db56f6e-b3c5-40cf-bf56-45704f295869",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias, training_loss, validation_losses = gradient_descent(X_train,\n",
    "                                                                   y_train,\n",
    "                                                                   1,\n",
    "                                                                   100\n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d0d3a98-1c0d-438f-b4dd-c1c5cf40741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-d110a210ccec>:48: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp / (tp + fp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.999354</td>\n",
       "      <td>0.896249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.135747</td>\n",
       "      <td>0.008126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.102133</td>\n",
       "      <td>0.004925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.082741</td>\n",
       "      <td>0.002627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.058177</td>\n",
       "      <td>0.001642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     threshold       tpr       fpr\n",
       "0         0.00  1.000000  1.000000\n",
       "1         0.01  1.000000  0.999918\n",
       "2         0.02  1.000000  0.976935\n",
       "3         0.03  1.000000  0.944349\n",
       "4         0.04  0.999354  0.896249\n",
       "..         ...       ...       ...\n",
       "96        0.96  0.135747  0.008126\n",
       "97        0.97  0.102133  0.004925\n",
       "98        0.98  0.082741  0.002627\n",
       "99        0.99  0.058177  0.001642\n",
       "100       1.00  0.000000  0.000000\n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roc_lr_val = make_roc_df(X_val, weights, y_val).loc[:, [\"threshold\", \"tpr\", \"fpr\"]]\n",
    "df_roc_lr_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f0f3faa-4517-4a2d-8830-9649f4ff4f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.956690</td>\n",
       "      <td>0.288188</td>\n",
       "      <td>0.668502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.948287</td>\n",
       "      <td>0.280473</td>\n",
       "      <td>0.667814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.951519</td>\n",
       "      <td>0.284577</td>\n",
       "      <td>0.666942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.959276</td>\n",
       "      <td>0.292867</td>\n",
       "      <td>0.666409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.942469</td>\n",
       "      <td>0.276205</td>\n",
       "      <td>0.666265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944349</td>\n",
       "      <td>0.055651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976935</td>\n",
       "      <td>0.023065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     threshold       tpr       fpr      diff\n",
       "33        0.33  0.956690  0.288188  0.668502\n",
       "35        0.35  0.948287  0.280473  0.667814\n",
       "34        0.34  0.951519  0.284577  0.666942\n",
       "32        0.32  0.959276  0.292867  0.666409\n",
       "36        0.36  0.942469  0.276205  0.666265\n",
       "..         ...       ...       ...       ...\n",
       "3         0.03  1.000000  0.944349  0.055651\n",
       "2         0.02  1.000000  0.976935  0.023065\n",
       "1         0.01  1.000000  0.999918  0.000082\n",
       "0         0.00  1.000000  1.000000  0.000000\n",
       "100       1.00  0.000000  0.000000  0.000000\n",
       "\n",
       "[101 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roc_lr_val[\"diff\"] = df_roc_lr_val[\"tpr\"] - df_roc_lr_val[\"fpr\"]\n",
    "\n",
    "df_roc_lr_val.sort_values([\"diff\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a5523fd-daa7-45f2-96c8-65247f131d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roc_lr_val.to_csv(\"LR_with_cv_roc_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844eb07-1724-420d-b252-2b90071d2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.line(df_roc_lr_val,\n",
    "        x=\"fpr\",\n",
    "        y=\"tpr\",\n",
    "        hover_data = [\"fpr\", \"tpr\", \"threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c77d23de-cc51-4aeb-8147-8c400ed5942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make plot of log-loss vs. epochs\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.plot(df_roc_lr_val[\"fpr\"], df_roc_lr_val[\"tpr\"], color=\"green\", \n",
    "        # marker=\"o\", \n",
    "        linestyle=\"solid\",\n",
    "        label=\"Logistic Regression\" \n",
    "       );\n",
    "# ax.plot(model_data[:, 1], model_data[:, 3], color=\"green\", marker=\"o\", linestyle=\"dashed\", label=\"Validation Set\");\n",
    "\n",
    "ax.plot(0.288188, 0.956690, color=\"green\", marker=\"o\")\n",
    "ax.set_xlabel(\"FPR\", fontsize=16)\n",
    "ax.set_ylabel(\"TPR\", fontsize=16)\n",
    "ax.set_title(f\"ROC for Optimized Logistic Regression (AUC = 0.90)\", \n",
    "             fontsize=18)\n",
    "\n",
    "ax.tick_params(axis=\"x\", labelsize=14)\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "\n",
    "ax.legend(fontsize=14)\n",
    "# ax.grid()\n",
    "font = {\n",
    "        # \"family\": \"Arial\",\n",
    "        # \"weight\": \"bold\",\n",
    "        \"size\": 14}\n",
    "\n",
    "plt.text(0.31, 0.90, \"Optimal Threshold = 0.33\", font)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf1a9c35-5953-4eed-9ff3-1851764a41d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8982541665161131"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_AUC(df_roc_lr_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
