{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a6e9bca-c873-4e38-9584-917d10928d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0708448e-08e2-4483-ae24-4d481cf262d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005218982696533203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa807a8a73b4e3c80f4130b350228d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# THE FIRST TIME YOU RUN THIS, IT MIGHT TAKE A WHILE\n",
    "model_path_or_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "# lora_path=False\n",
    "# lora_path = \"./mistral-7b-int4-dolly/checkpoint-82\" # BAD\n",
    "# lora_path = \"./mistral-7b-int4-dolly/checkpoint-80\" # BAD\n",
    "# lora_path = \"./mistral-7b-int4-dolly_SMALL/checkpoint-16\" # 400 samples BAD\n",
    "# lora_path = \"./mistral-7b-int4-dolly_SMALL/\" # 400 samples BAD\n",
    "# lora_path = \"./mistral-7b-int4-dolly_SMALL_V2/\" # 1000 samples BAD\n",
    "# lora_path = \"./mistral-7b-int4-dolly_SMALL_400_3epochs/\" # BAD - non-blank context only\n",
    "# lora_path = \"./mistral-7b-int4-dolly_FULL_3279_1epochs/\" # BAD - non-blank context only\n",
    "# lora_path = \"./mistral-7b-int4-dolly_FULL_3279_1epochs/checkpoint-62\" # BAD - non-blank context only\n",
    "# lora_path = \"./mistral-7b-int4-dolly_FULL_3279_1epochs_r8_alpha8/\" # BAD\n",
    "# lora_path = \"./mistral-7b-int4-dolly_FULL_3279_1epochs_r16_alpha32_lr1e-4\" # BAD\n",
    "# lora_path = \"./mistral-7b-int4-dolly_summarization\" # BAD\n",
    "# lora_path= \"./mistral-7b-int4-dolly_summarization_r16_a16_ep3_LR1e3_datacampv1/checkpoint-22\" # BAD\n",
    "# lora_path=\"./mistral-7b-int4-dolly_summarization_r8_a16_ep1_LR1e3_datacampv2_redproj\" # BAD\n",
    "# lora_path=\"./mistral-7b-int4-dolly_summarization_r8_a16_ep1_LR1e3_blankcontextallowed\"\n",
    "# lora_path=\"./mistral-7b-int4-dolly_summarization_r8_a16_ep1_LR1e3_qkvo_projonly\" # has only 1000 now and unk-token padded\n",
    "# lora_path=\"./mistral-7b-int4-dolly_summarization_r8_a16_ep1_LR1e3_qkvo_fixedtokens\" # best\n",
    "# lora_path=\"./mistral-7b-int4-dolly_summarization_r8_a16_ep1_LR1e3_qkvo_fixedtokens_state_sourcev1/checkpoint-82\"\n",
    "# lora_path=\"./mistral-7b-int4-dolly_summarization_r8_a16_ep1_LR1e3_qkvo_fixedtokens_state_sourcev2\"\n",
    "lora_path=\"./mistral-7b-int4-dolly_summarization_r8_a16_ep1_LR1e3_allproj_fixedtokens\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False, # AP: For nested quantization\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "if lora_path:\n",
    "    # load base LLM model with PEFT Adapter\n",
    "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "        lora_path,\n",
    "        low_cpu_mem_usage=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        use_flash_attention_2=True,\n",
    "        # attn_implementation=\"flash_attention_2\",\n",
    "        quantization_config = bnb_config\n",
    "    )\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(lora_path)\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(lora_path, padding_side='left')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(lora_path, padding_side='right') # AP: ADDED\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path_or_id,\n",
    "        low_cpu_mem_usage=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        # use_flash_attention_2=True,\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        quantization_config = bnb_config\n",
    "    )\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(model_path_or_id)\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(model_path_or_id, padding_side='left')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path_or_id, padding_side='right')  # AP: ADDED\n",
    "\n",
    "def generate(prompt, max_new_tokens = 100, temperature = 0.7):\n",
    "    \"\"\"Convenience function for generating model output\"\"\"\n",
    "    # Tokenize the input\n",
    "    input_ids = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True).input_ids.cuda()\n",
    "    \n",
    "    # Generate new tokens based on the prompt, up to max_new_tokens\n",
    "    # Sample aacording to the parameter\n",
    "    with torch.inference_mode(mode=True): # AP: added mode=True\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids, \n",
    "            max_new_tokens=max_new_tokens, \n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=temperature,\n",
    "            use_cache=True,\n",
    "            pad_token_id=tokenizer.eos_token_id ## ADDED - AP\n",
    "        )\n",
    "    return tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cecf564d-3522-43bb-854c-65be6c55fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The connection to the database\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(\n",
    "    driver= \"psycopg2\",\n",
    "    host = \"localhost\",\n",
    "    port = \"5432\",\n",
    "    database = \"postgres\",\n",
    "    user= \"username\",\n",
    "    password=\"password\"\n",
    ")\n",
    "\n",
    "# The embedding function that will be used to store into the database\n",
    "embedding_function = SentenceTransformerEmbeddings(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "    model_kwargs = {'device': 'cuda'},\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# Creates the database connection to our existing DB\n",
    "db = PGVector(\n",
    "    connection_string = CONNECTION_STRING,\n",
    "    collection_name = \"embeddings\",\n",
    "    embedding_function = embedding_function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e1271-a05d-4b7c-81b0-22e8cef70825",
   "metadata": {},
   "source": [
    "### Print sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af541fea-79ba-4586-b4b9-f572cb988880",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who can you think of works at the clinic?\"\n",
    "\n",
    "docs_with_scores = db.similarity_search_with_score(question, k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d027e64-3aad-4fb8-9afb-1bd66fd8f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_RAG_sources_and_pages(docs_input):\n",
    "    \"\"\"\n",
    "    Concatenate and list sources+pages for multiple documents in RAG\n",
    "    \"\"\"\n",
    "    \n",
    "    concat_source_lst = []\n",
    "    for tup in docs_input:\n",
    "        doc_source = re.search('(MSL .{1,})', tup[0].metadata[\"source\"])[0]\n",
    "        doc_page = tup[0].metadata[\"page\"]\n",
    "        \n",
    "        source_page = f\"{doc_source}, page = {doc_page}\"\n",
    "        concat_source_lst.append(source_page)\n",
    "        \n",
    "    concat_source_lst.sort()        \n",
    "    concat_source_info = \"; \".join(concat_source_lst)\n",
    "    \n",
    "    return concat_source_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae96a25e-f0c4-4be6-bcea-a78af685184a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '../../msl-data/MSL Notes_4.pdf', 'page': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "docs_with_scores[0][0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f96d47d-9b04-4f9d-8e61-6a083edef144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../msl-data/MSL Notes_4.pdf\n",
      "../../msl-data/MSL Notes_1.pdf\n",
      "../../msl-data/MSL Notes_4.pdf\n"
     ]
    }
   ],
   "source": [
    "for tup in docs_with_scores:\n",
    "    print(tup[0].metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2466c6a4-7cc3-4335-9010-e94975ce68ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSL Notes_1.pdf, page = 0; MSL Notes_4.pdf, page = 0; MSL Notes_4.pdf, page = 1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_RAG_sources_and_pages(docs_with_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b794ea8c-8ebc-4f4d-9f72-e5fedd414549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5062807489131533"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_scores[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "547873e4-54c5-4593-bf67-16d294f6694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What is the efficacy of NeuroGlyde?\n",
      "\n",
      "Generated Response:\n",
      "NeuroGlyde has been shown to be effective in reducing annualized relapse rates by 40% in multiple sclerosis patients. It has also been shown to improve quality of life measures.\n",
      "\n",
      "Answer provided by AP.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RAG_PROMPT_TEMPLATE = \"\"\"### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "Using only the context above, {question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "empty_context = \"\"\n",
    "question = \"What is the efficacy of NeuroGlyde?\"\n",
    "# question = \"What is the efficacy of Aetherisol?\"\n",
    "# question = \"What kind of doctor is Michael Chang?\"\n",
    "# question=\"What does Gastroguard treat?\"\n",
    "# question = \"What clinic does Jonathan Reynolds work at?\"\n",
    "\n",
    "# question = \"What is Aetherisol used to treat?\"\n",
    "# question=\"What is the mechanism of action for Gastroguard?\"\n",
    "# question=\"What is a drug name for treating gastric medical problems and what does it treat?\"\n",
    "\n",
    "\n",
    "docs_with_scores = db.similarity_search_with_score(question, k = 2)\n",
    "context_prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "    context = docs_with_scores[0][0].page_content,\n",
    "    question = question\n",
    ")\n",
    "\n",
    "res = generate(context_prompt, max_new_tokens = 1000, temperature = 0.4)\n",
    "\n",
    "print(f\"Question:\\n{question}\\n\")\n",
    "print(f\"Generated Response:\\n{res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612e76f-e5ae-4242-8e8b-5179354bbd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76452419-d12c-46e9-b40c-210da5862632",
   "metadata": {},
   "source": [
    "### Add source? 10Feb2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cae118-10a1-43dd-b1e1-5c058e25d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6ab3a14-b1f8-4a6c-be36-fce17ea2f6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../msl-data/MSL Notes_32.pdf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_scores[0][0].metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19393f2c-7b89-4dae-939c-88ce32b308c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5452ff96-0d24-4151-94c7-8d856848d579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSL Notes_32.pdf'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re.search(\"(MSL .{1,})\", docs_with_scores[0][0].metadata[\"source\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15d05170-d129-493a-8090-e61d2ce0d9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What clinic does Jonathan Reynolds work?\n",
      "\n",
      "Generated Response:\n",
      "RespiraLung Pulmonary Clinic\n",
      "\n",
      "### Source:\n",
      "Source is: Medical.pdf\n",
      "\n",
      "Answer provided by AP.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "### NEW PROMPT ###\n",
    "RAG_PROMPT_TEMPLATE = \"\"\"### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "Using only the context above, {question}. Provide the source of response below.\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "empty_context = \"\"\n",
    "# question = \"What is the efficacy of NeuroGlyde?\"\n",
    "# question = \"What is the efficacy of Aetherisol?\"\n",
    "# question = \"What kind of doctor is Michael Chang?\"\n",
    "# question=\"What does GastriGuard do?\"\n",
    "question = \"What clinic does Jonathan Reynolds work?\"\n",
    "\n",
    "docs_with_scores = db.similarity_search_with_score(question, k = 1)\n",
    "context_prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "    context = docs_with_scores[0][0].page_content,\n",
    "    question = question,\n",
    "    source_filename = re.search(\"(MSL .{1,})\", docs_with_scores[0][0].metadata[\"source\"])[0]\n",
    ")\n",
    "\n",
    "res = generate(context_prompt, max_new_tokens = 300, temperature = 0.2)\n",
    "\n",
    "print(f\"Question:\\n{question}\\n\")\n",
    "print(f\"Generated Response:\\n{res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b376e6-0f3c-4031-a4ae-4fe4d5d76e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " temp = 0.2\n",
      "Question:\n",
      "What is the efficacy of NeuroGlyde?\n",
      "\n",
      "Generated Response:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " temp = 0.4\n",
      "Question:\n",
      "What is the efficacy of NeuroGlyde?\n",
      "\n",
      "Generated Response:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " temp = 0.6\n",
      "Question:\n",
      "What is the efficacy of NeuroGlyde?\n",
      "\n",
      "Generated Response:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " temp = 0.8\n",
      "Question:\n",
      "What is the efficacy of NeuroGlyde?\n",
      "\n",
      "Generated Response:\n",
      "\n",
      "\n",
      " temp = 1.0\n",
      "Question:\n",
      "What is the efficacy of NeuroGlyde?\n",
      "\n",
      "Generated Response:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RAG_PROMPT_TEMPLATE = \"\"\"### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "Using only the context above, {question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "# empty_context = \"\"\n",
    "question = \"What is the efficacy of NeuroGlyde?\"\n",
    "# question = \"What is the efficacy of Aetherisol?\"\n",
    "# question = \"What kind of doctor is Michael Chang?\"\n",
    "\n",
    "docs_with_scores = db.similarity_search_with_score(question, k = 1)\n",
    "context_prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "    context = docs_with_scores[0][0].page_content,\n",
    "    question = question\n",
    ")\n",
    "\n",
    "for temp in range(2, 10+1, 2):\n",
    "    res = generate(context_prompt, max_new_tokens = 100, temperature = temp/10)\n",
    "    print(f\" temp = {temp/10}\")\n",
    "    print(f\"Question:\\n{question}\\n\")\n",
    "    print(f\"Generated Response:\\n{res}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d943eb34-a6d3-4252-a40c-a13ed269ddbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17dbbae5-0e7f-4b2e-9e86-27b017c5a0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content=\"Subject:  Medical Science Liaison (MSL) Notes - In-Depth Discussion on NeuroGlyde  \\nDate:  April 10, 2023  \\nProvider:  Dr. James Harper  \\nTitle:  Neurologist  \\nInstitution:  City Neurology Clinic  \\nSummary of Key Discussion Points:  \\n1. Introduction:  \\n• Introduced NeuroGlyde, a novel neuroprotective agent, emphasizing its potential in \\nslowing disease progression.  \\n• Discussed ongoing clinical trials and positive early -phase results.  \\n2. Provider's Current Patient C ases:  \\n• Explored Dr. Harper's experience with NeuroGlyde in treating neurodegenerative \\ndisorders.  \\n• Discussed improvements in cognitive function observed in Alzheimer's patients.  \\n3. Efficacy and Clinical Data:  \\n• Presented data demonstrating a 40% reduction in annualized relapse rates in multiple \\nsclerosis patients.  \\n• Highlighted significant improvements in quality of life measures.  \\n4. Safety Profile:  \\n• Discussed the favorable safety profile of NeuroGlyde, with no serious  adverse events \\nreported in long -term studies.  \\n• Addressed concerns related to potential neurological side effects.  \\n5. Mechanism of Action:  \\n• Explained NeuroGlyde's unique mechanism targeting neuroinflammation.  \\n• Quantified its efficacy by discussing a 30% reductio n in inflammatory biomarkers.  \\n6. Patient Adherence and Education:  \\n• Explored strategies for enhancing patient adherence, including simplified dosing \\nregimens.  \\n• Shared educational materials tailored for both patients and caregivers.  \\n7. Emerging Research and Future D evelopments:  \\n• Highlighted ongoing research on NeuroGlyde's potential in Parkinson's disease.  \\n• Discussed plans for expanded access programs and patient registries.  \\n8. Competitive Landscape:\", metadata={'source': '../../msl-data/MSL Notes_2.pdf', 'page': 0}),\n",
       "  0.2652739724353451)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc92ef50-4e0f-4873-955a-55a22420841a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('### Context:\\n'\n",
      " 'Subject:  Medical Science Liaison (MSL) Notes - In-Depth Discussion on '\n",
      " 'NeuroGlyde  \\n'\n",
      " 'Date:  April 10, 2023  \\n'\n",
      " 'Provider:  Dr. James Harper  \\n'\n",
      " 'Title:  Neurologist  \\n'\n",
      " 'Institution:  City Neurology Clinic  \\n'\n",
      " 'Summary of Key Discussion Points:  \\n'\n",
      " '1. Introduction:  \\n'\n",
      " '• Introduced NeuroGlyde, a novel neuroprotective agent, emphasizing its '\n",
      " 'potential in \\n'\n",
      " 'slowing disease progression.  \\n'\n",
      " '• Discussed ongoing clinical trials and positive early -phase results.  \\n'\n",
      " \"2. Provider's Current Patient C ases:  \\n\"\n",
      " \"• Explored Dr. Harper's experience with NeuroGlyde in treating \"\n",
      " 'neurodegenerative \\n'\n",
      " 'disorders.  \\n'\n",
      " \"• Discussed improvements in cognitive function observed in Alzheimer's \"\n",
      " 'patients.  \\n'\n",
      " '3. Efficacy and Clinical Data:  \\n'\n",
      " '• Presented data demonstrating a 40% reduction in annualized relapse rates '\n",
      " 'in multiple \\n'\n",
      " 'sclerosis patients.  \\n'\n",
      " '• Highlighted significant improvements in quality of life measures.  \\n'\n",
      " '4. Safety Profile:  \\n'\n",
      " '• Discussed the favorable safety profile of NeuroGlyde, with no serious  '\n",
      " 'adverse events \\n'\n",
      " 'reported in long -term studies.  \\n'\n",
      " '• Addressed concerns related to potential neurological side effects.  \\n'\n",
      " '5. Mechanism of Action:  \\n'\n",
      " \"• Explained NeuroGlyde's unique mechanism targeting neuroinflammation.  \\n\"\n",
      " '• Quantified its efficacy by discussing a 30% reductio n in inflammatory '\n",
      " 'biomarkers.  \\n'\n",
      " '6. Patient Adherence and Education:  \\n'\n",
      " '• Explored strategies for enhancing patient adherence, including simplified '\n",
      " 'dosing \\n'\n",
      " 'regimens.  \\n'\n",
      " '• Shared educational materials tailored for both patients and caregivers.  \\n'\n",
      " '7. Emerging Research and Future D evelopments:  \\n'\n",
      " \"• Highlighted ongoing research on NeuroGlyde's potential in Parkinson's \"\n",
      " 'disease.  \\n'\n",
      " '• Discussed plans for expanded access programs and patient registries.  \\n'\n",
      " '8. Competitive Landscape:\\n'\n",
      " '\\n'\n",
      " '### Question:\\n'\n",
      " 'Using only the context above, What is the efficacy of NeuroGlyde?\\n'\n",
      " '\\n'\n",
      " '### Response:\\n')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(context_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d58b5a-4a72-4d97-953c-aceb754ae238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1825"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fffad5b-66de-4ad8-ae54-f90baccd12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, max_new_tokens = 100, temperature = 0.7):\n",
    "    \"\"\"Convenience function for generating model output\"\"\"\n",
    "    # Tokenize the input\n",
    "    input_ids = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True).input_ids.cuda()\n",
    "    \n",
    "    # Generate new tokens based on the prompt, up to max_new_tokens\n",
    "    # Sample aacording to the parameter\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids, \n",
    "            max_new_tokens=max_new_tokens, \n",
    "            do_sample=True, \n",
    "            top_p=0.9,\n",
    "            temperature=temperature,\n",
    "            use_cache=True\n",
    "        )\n",
    "    return tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b11ccb-32be-4b3c-844f-0701bf48a1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "res = generate(context_prompt, max_new_tokens = 100, temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff8992e-950d-4e3e-a83e-e818445becd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_check = tokenizer(context_prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaca488a-2826-441e-b346-216441bc7285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids_check, \n",
    "            max_new_tokens=100, \n",
    "            do_sample=True, \n",
    "            top_p=0.9,\n",
    "            temperature=0.1,\n",
    "            use_cache=True\n",
    "        )\n",
    "        \n",
    "tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(context_prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ef3a63d-b340-4f5c-b789-945744d3c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_check = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ddc6ff9-4296-4d99-87b8-5aa1ce0e1b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   774, 14268, 28747,    13, 22210, 28747, 28705, 12195,  9323,\n",
       "           393,   515,  2350,   325,  3477, 28758, 28731, 16254,   387,   560,\n",
       "         28733, 17603,  3433, 18637,   356,  3147,  2138, 28777,   346,   450,\n",
       "           259,    13,  3465, 28747, 28705,  3999, 28705, 28740, 28734, 28725,\n",
       "         28705, 28750, 28734, 28750, 28770,   259,    13,  5342, 28747, 28705,\n",
       "          2985, 28723,  4797, 23649,   259,    13,  7522, 28747, 28705,  3147,\n",
       "         28718, 22068,   392,   259,    13,  6060,  6529, 28747, 28705,  3805,\n",
       "          3147, 28718,  1438,  8677, 19950,   294,   259,    13, 17590,   302,\n",
       "          7388,  3433, 18637, 24304, 28747,   259,    13, 28740, 28723, 23628,\n",
       "         28747,   259,    13, 28899,  4666,  3399,  1354,  3147,  2138, 28777,\n",
       "           346,   450, 28725,   264,  7092, 20342,  8716,   310,   495,  8073,\n",
       "         28725, 10574,  3864,   871,  4628,   297, 28705,    13,  2181, 15675,\n",
       "          8030,  5097,   296, 28723,   259,    13, 28899,  3433, 12804,   286,\n",
       "         15260, 15193, 19993,   304,  5278,  2935,   387, 19525,  2903, 28723,\n",
       "           259,    13, 28750, 28723,  1133,  4340, 28742, 28713, 10929,  4186,\n",
       "           722,   334,   390,   274, 28747,   259,    13, 28899, 13702,  2455,\n",
       "          2985, 28723, 23649, 28742, 28713,  2659,   395,  3147,  2138, 28777,\n",
       "           346,   450,   297, 22656, 20342,   450,  4506,  1197, 28705,    13,\n",
       "          2021, 10486, 28723,   259,    13, 28899,  3433, 12804,   286, 19664,\n",
       "           297, 25746,   908,  7975,   297,   976, 28764, 24556, 28742, 28713,\n",
       "          6883, 28723,   259,    13, 28770, 28723,   413, 21533,  2426,   304,\n",
       "         19950,   745,  5284, 28747,   259,    13, 28899, 21073,   286,  1178,\n",
       "          6695,  1077,   264, 28705, 28781, 28734, 28823, 13388,   297,  9558,\n",
       "          1332,  1016,  9772,  7978,   297,  5166, 28705,    13, 28713,   512,\n",
       "           263,  9795,  6883, 28723,   259,    13, 28899,  4556,  3646,   286,\n",
       "          5864, 19664,   297,  4045,   302,  1411, 10582, 28723,   259,    13,\n",
       "         28781, 28723, 19412, 23538, 28747,   259,    13, 28899,  3433, 12804,\n",
       "           286,   272,  4268,   522,  6661,  7741,   302,  3147,  2138, 28777,\n",
       "           346,   450, 28725,   395,   708,  4592, 28705,   616,  4177,  3926,\n",
       "         28705,    13, 10146,   286,   297,  1043,   387,  6590,  7193, 28723,\n",
       "           259,    13, 28899,  3301, 10025, 10864,  5202,   298,  4628, 21194,\n",
       "         22068,   745,  2081,  6092, 28723,   259,    13, 28782, 28723, 27164,\n",
       "          1443,   302,  9624, 28747,   259,    13, 28899, 13702,  1738,  3147,\n",
       "          2138, 28777,   346,   450, 28742, 28713,  4842, 14175,  2718,   288,\n",
       "         20342, 21255,  6461,   352, 28723,   259,    13, 28899, 22655,  1799,\n",
       "           871,  1397,   294,  2426,   486, 20633,   264, 28705, 28770, 28734,\n",
       "         28823,   312,  2478,   691,   307,   297,  3661,   314,  3076,   695,\n",
       "          4240,   300,   719,   404, 28723,   259,    13, 28784, 28723,  4186,\n",
       "           722,  1964,   663,   636,   304,  9352, 28747,   259,    13, 28899,\n",
       "         13702,  2455, 12108,   354,  8050,  7161,  7749,   616,   663,   636,\n",
       "         28725,  2490,  9878,  1799,  4882,   288, 28705,    13,  1376,   321,\n",
       "           596, 28723,   259,    13, 28899,  1295,  1327, 14165,  7069,  8675,\n",
       "          2455,   354,  1560,  6883,   304,  1656, 28721,  1588, 28723,   259,\n",
       "            13, 28787, 28723, 16762,  3080,  7982,   304, 18242,   384,   683,\n",
       "           301,   410,  1339, 28747,   259,    13, 28899,  4556,  3646,   286,\n",
       "         15260,  3332,   356,  3147,  2138, 28777,   346,   450, 28742, 28713,\n",
       "          4628,   297,  4120, 11827, 28742, 28713,  8030, 28723,   259,    13,\n",
       "         28899,  3433, 12804,   286,  6400,   354, 14708,  2735,  7034,   304,\n",
       "          7749,   983,   392,  2040, 28723,   259,    13, 28783, 28723, 17830,\n",
       "          2468,  5062,  8951, 28747,    13,    13, 27332, 22478, 28747,    13,\n",
       "         26021,   865,   272,  2758,  2747, 28725,  1824,   349,   272,  1397,\n",
       "           294,  2426,   302,  3147,  2138, 28777,   346,   450, 28804,    13,\n",
       "            13, 27332, 12107, 28747,    13,     2]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1857b45-8089-4c86-83e1-1ff78423f214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    outputs_check = model.generate(\n",
    "            input_ids=input_ids_check, \n",
    "            max_new_tokens=100, \n",
    "            do_sample=True, \n",
    "            top_p=0.9,\n",
    "            temperature=0.1,\n",
    "            use_cache=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9789c44e-0745-4604-abbe-823477c71bd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs_check' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\u001b[43moutputs_check\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs_check' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs_check.detach().cpu().numpy(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4435502-7c83-49a9-aa9e-f4e72b60614e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ### Context:\\nSubject:  Medical Science Liaison (MSL) Notes - In -Depth Discussion on NeuroGlyde  \\nDate:  April 10, 2023  \\nProvider:  Dr. James Harper  \\nTitle:  Neurologist  \\nInstitution:  City Neurology Clinic  \\nSummary of Key Discussion Points:  \\n1. Introduction:  \\n• Introduced NeuroG'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(context_prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed6ac465-980e-40d3-8db9-c9b6e513622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   774, 14268, 28747,    13, 22210, 28747, 28705, 12195,  9323,\n",
       "           393,   515,  2350,   325,  3477, 28758, 28731, 16254,   387,   560,\n",
       "         28733, 17603,  3433, 18637,   356,  3147,  2138, 28777,   346,   450,\n",
       "           259,    13,  3465, 28747, 28705,  3999, 28705, 28740, 28734, 28725,\n",
       "         28705, 28750, 28734, 28750, 28770,   259,    13,  5342, 28747, 28705,\n",
       "          2985, 28723,  4797, 23649,   259,    13,  7522, 28747, 28705,  3147,\n",
       "         28718, 22068,   392,   259,    13,  6060,  6529, 28747, 28705,  3805,\n",
       "          3147, 28718,  1438,  8677, 19950,   294,   259,    13, 17590,   302,\n",
       "          7388,  3433, 18637, 24304, 28747,   259,    13, 28740, 28723, 23628,\n",
       "         28747,   259,    13, 28899,  4666,  3399,  1354,  3147,  2138, 28777,\n",
       "           346,   450, 28725,   264,  7092, 20342,  8716,   310,   495,  8073,\n",
       "         28725, 10574,  3864,   871,  4628,   297, 28705,    13,  2181, 15675,\n",
       "          8030,  5097,   296, 28723,   259,    13, 28899,  3433, 12804,   286,\n",
       "         15260, 15193, 19993,   304,  5278,  2935,   387, 19525,  2903, 28723,\n",
       "           259,    13, 28750, 28723,  1133,  4340, 28742, 28713, 10929,  4186,\n",
       "           722,   334,   390,   274, 28747,   259,    13, 28899, 13702,  2455,\n",
       "          2985, 28723, 23649, 28742, 28713,  2659,   395,  3147,  2138, 28777,\n",
       "           346,   450,   297, 22656, 20342,   450,  4506,  1197, 28705,    13,\n",
       "          2021, 10486, 28723,   259,    13, 28899,  3433, 12804,   286, 19664,\n",
       "           297, 25746,   908,  7975,   297,   976, 28764, 24556, 28742, 28713,\n",
       "          6883, 28723,   259,    13, 28770, 28723,   413, 21533,  2426,   304,\n",
       "         19950,   745,  5284, 28747,   259,    13, 28899, 21073,   286,  1178,\n",
       "          6695,  1077,   264, 28705, 28781, 28734, 28823, 13388,   297,  9558,\n",
       "          1332,  1016,  9772,  7978,   297,  5166, 28705,    13, 28713,   512,\n",
       "           263,  9795,  6883, 28723,   259,    13, 28899,  4556,  3646,   286,\n",
       "          5864, 19664,   297,  4045,   302,  1411, 10582, 28723,   259,    13,\n",
       "         28781, 28723, 19412, 23538, 28747,   259,    13, 28899,  3433, 12804,\n",
       "           286,   272,  4268,   522,  6661,  7741,   302,  3147,  2138, 28777,\n",
       "           346,   450, 28725,   395,   708,  4592, 28705,   616,  4177,  3926,\n",
       "         28705,    13, 10146,   286,   297,  1043,   387,  6590,  7193, 28723,\n",
       "           259,    13, 28899,  3301, 10025, 10864,  5202,   298,  4628, 21194,\n",
       "         22068,   745,  2081,  6092, 28723,   259,    13, 28782, 28723, 27164,\n",
       "          1443,   302,  9624, 28747,   259,    13, 28899, 13702,  1738,  3147,\n",
       "          2138, 28777,   346,   450, 28742, 28713,  4842, 14175,  2718,   288,\n",
       "         20342, 21255,  6461,   352, 28723,   259,    13, 28899, 22655,  1799,\n",
       "           871,  1397,   294,  2426,   486, 20633,   264, 28705, 28770, 28734,\n",
       "         28823,   312,  2478,   691,   307,   297,  3661,   314,  3076,   695,\n",
       "          4240,   300,   719,   404, 28723,   259,    13, 28784, 28723,  4186,\n",
       "           722,  1964,   663,   636,   304,  9352, 28747,   259,    13, 28899,\n",
       "         13702,  2455, 12108,   354,  8050,  7161,  7749,   616,   663,   636,\n",
       "         28725,  2490,  9878,  1799,  4882,   288, 28705,    13,  1376,   321,\n",
       "           596, 28723,   259,    13, 28899,  1295,  1327, 14165,  7069,  8675,\n",
       "          2455,   354,  1560,  6883,   304,  1656, 28721,  1588, 28723,   259,\n",
       "            13, 28787, 28723, 16762,  3080,  7982,   304, 18242,   384,   683,\n",
       "           301,   410,  1339, 28747,   259,    13, 28899,  4556,  3646,   286,\n",
       "         15260,  3332,   356,  3147,  2138, 28777,   346,   450, 28742, 28713,\n",
       "          4628,   297,  4120, 11827, 28742, 28713,  8030, 28723,   259,    13,\n",
       "         28899,  3433, 12804,   286,  6400,   354, 14708,  2735,  7034,   304,\n",
       "          7749,   983,   392,  2040, 28723,   259,    13, 28783, 28723, 17830,\n",
       "          2468,  5062,  8951, 28747,    13,    13, 27332, 22478, 28747,    13,\n",
       "         26021,   865,   272,  2758,  2747, 28725,  1824,   349,   272,  1397,\n",
       "           294,  2426,   302,  3147,  2138, 28777,   346,   450, 28804,    13,\n",
       "            13, 27332, 12107, 28747,    13,     2,     2]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
